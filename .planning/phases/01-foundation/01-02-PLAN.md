---
phase: 01-foundation
plan: 02
type: execute
wave: 2
depends_on: ["01-01"]
files_modified:
  - src/lib/compositor.ts
  - src/components/DropZone.tsx
  - src/components/ModelProgress.tsx
  - src/components/ResultView.tsx
  - src/components/App.tsx
autonomous: false

must_haves:
  truths:
    - "User can drop a single image file onto the drop zone and processing begins automatically"
    - "First-time visitor sees model download progress bar with MB loaded / total MB and 'one-time download' text"
    - "After processing, user sees the background-removed PNG result at full original resolution"
    - "UI remains interactive (no freezes) during model download and image inference"
    - "crossOriginIsolated === true is visible in the app UI when served via dev server"
    - "Zero network requests occur during image processing (model was already downloaded)"
  artifacts:
    - path: "src/lib/compositor.ts"
      provides: "Full-resolution Canvas compositing: scales model-res mask to original dims, applies alpha, exports PNG Blob"
      exports: ["compositeFullResolution"]
      min_lines: 40
    - path: "src/components/DropZone.tsx"
      provides: "Drag-and-drop zone accepting a single image file"
      min_lines: 20
    - path: "src/components/ModelProgress.tsx"
      provides: "Model download progress bar with MB loaded, total, and one-time download messaging"
      min_lines: 15
    - path: "src/components/ResultView.tsx"
      provides: "Displays processed image result with download link"
      min_lines: 15
    - path: "src/components/App.tsx"
      provides: "Full wiring: Worker creation, state management, drop -> process -> display flow"
      min_lines: 60
  key_links:
    - from: "src/components/App.tsx"
      to: "src/workers/inference.worker.ts"
      via: "new Worker(new URL()) pattern -- MUST be inline, not abstracted"
      pattern: "new Worker.*new URL.*inference\\.worker"
    - from: "src/components/App.tsx"
      to: "src/lib/compositor.ts"
      via: "compositeFullResolution() call after receiving mask data from worker"
      pattern: "compositeFullResolution"
    - from: "src/components/App.tsx"
      to: "src/components/DropZone.tsx"
      via: "onFileDrop callback prop"
      pattern: "onFileDrop|onDrop"
    - from: "src/lib/compositor.ts"
      to: "OffscreenCanvas"
      via: "Creates OffscreenCanvas for mask scaling and compositing, shrinks after use"
      pattern: "new OffscreenCanvas"
---

<objective>
Build the Canvas compositor for full-resolution output and wire the complete end-to-end flow: user drops image -> Worker processes it -> compositor produces full-res PNG -> result displayed.

Purpose: This completes Phase 1 by connecting the AI pipeline (from Plan 01) to a minimal but functional UI. After this plan, a user can actually drop an image and get a background-removed result -- proving the entire concept works in-browser.

Output: Working end-to-end single-image background removal. User drops an image, sees model download progress (first time) or immediate processing (cached), and gets a full-resolution transparent PNG result.
</objective>

<execution_context>
@/Users/wojciecholszak/.claude/get-shit-done/workflows/execute-plan.md
@/Users/wojciecholszak/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-foundation/01-RESEARCH.md
@.planning/phases/01-foundation/01-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Canvas compositor for full-resolution mask compositing</name>
  <files>
    src/lib/compositor.ts
  </files>
  <action>
    Implement `compositeFullResolution()` following the research pattern (Pattern 3 in RESEARCH.md):

    ```typescript
    export async function compositeFullResolution(
      originalBlob: Blob,
      maskData: { data: Uint8ClampedArray; width: number; height: number; channels: number }
    ): Promise<Blob>
    ```

    Implementation steps:
    1. Load the original image at full resolution using `createImageBitmap(originalBlob)`. Extract `origW` and `origH`.

    2. Create an OffscreenCanvas at the mask's model resolution (maskData.width x maskData.height). Put the mask RGBA data onto it using `putImageData(new ImageData(new Uint8ClampedArray(maskData.data), maskData.width, maskData.height), 0, 0)`. IMPORTANT: Must create a NEW Uint8ClampedArray from maskData.data because the original buffer may be neutered after Transferable postMessage.

    3. Create a second OffscreenCanvas at original resolution (origW x origH). Draw the mask canvas scaled to original dimensions using `drawImage(maskCanvas, 0, 0, origW, origH)`. Extract the scaled mask pixel data with `getImageData()`.

    4. Create a third OffscreenCanvas at original resolution. Draw the original image with `drawImage(originalBitmap, 0, 0)`. Get the pixel data.

    5. Apply the mask: Loop through every pixel (stride 4). Copy the alpha channel from the scaled mask (`maskPixels[i + 3]`) to the output pixels (`outputPixels[i + 3]`).

    6. Put the modified pixel data back and export as PNG: `outputCanvas.convertToBlob({ type: "image/png" })`.

    7. CRITICAL -- Memory cleanup: After extracting the Blob, shrink ALL three OffscreenCanvases to release GPU/canvas memory:
    ```typescript
    maskCanvas.width = 1; maskCanvas.height = 1;
    scaledMaskCanvas.width = 1; scaledMaskCanvas.height = 1;
    outputCanvas.width = 1; outputCanvas.height = 1;
    ```
    Also call `originalBitmap.close()` to release the ImageBitmap.

    This pattern is critical for iOS Safari which has a ~224-384 MB total canvas memory ceiling.

    Do NOT use `toDataURL()` -- always use `convertToBlob()` (33% smaller, no base64 overhead, no URL length limits).
  </action>
  <verify>
    1. `npx vite build` succeeds -- compositor compiles cleanly
    2. `compositeFullResolution` is exported as a named export
    3. File contains `new OffscreenCanvas` (at least 2 instances)
    4. File contains canvas memory cleanup (`.width = 1`)
    5. File contains `convertToBlob` (not `toDataURL`)
    6. File contains `originalBitmap.close()`
  </verify>
  <done>
    Compositor function accepts original Blob + mask data, produces full-resolution PNG Blob with transparent background. All OffscreenCanvases and ImageBitmaps are cleaned up after use. No toDataURL usage.
  </done>
</task>

<task type="auto">
  <name>Task 2: Minimal drop zone UI + end-to-end wiring</name>
  <files>
    src/components/DropZone.tsx
    src/components/ModelProgress.tsx
    src/components/ResultView.tsx
    src/components/App.tsx
  </files>
  <action>
    Build the minimal UI components and wire the complete flow in App.tsx.

    **src/components/DropZone.tsx:**
    - A styled drop zone that accepts a single image file (PNG, JPG, WebP).
    - Implements native HTML5 drag-and-drop: onDragOver (preventDefault + visual feedback), onDragLeave, onDrop (extract first File from dataTransfer.files).
    - Also includes a hidden file input with a "Browse" button as fallback.
    - Validates file type (image/png, image/jpeg, image/webp). Shows error text for invalid types.
    - Props: `onFileDrop: (file: File) => void`, `disabled: boolean` (disabled during processing).
    - Styling: Tailwind classes. Dashed border, centered text "Drop an image here", drag-over highlight state (blue border + light blue bg). Keep it functional, not fancy -- Phase 2 handles visual polish.

    **src/components/ModelProgress.tsx:**
    - Shows model download progress when status is "downloading".
    - Props: `status: ModelStatus`, `progress: DownloadProgress | null`.
    - When status === "downloading" and progress exists: Show a progress bar with `{(progress.loaded / 1024 / 1024).toFixed(1)} MB / {(progress.total / 1024 / 1024).toFixed(1)} MB` text. Show "Downloading AI model (one-time only)" message.
    - When status === "downloading" and progress is null: Show "Initializing AI model..." with indeterminate state.
    - When status === "ready": Show "AI model ready" with a green check.
    - When status === "error": Show error state with red styling.
    - Styling: Simple Tailwind progress bar (div inside div with width percentage).

    **src/components/ResultView.tsx:**
    - Displays the processed image result.
    - Props: `resultUrl: string | null` (Blob URL), `originalName: string`.
    - When resultUrl exists: Show the image via `<img src={resultUrl}>` with max dimensions. Show a download button/link using `<a href={resultUrl} download={originalName.replace(/\.[^.]+$/, '_nobg.png')}>Download PNG</a>`.
    - Show a "Process another" button that calls an `onReset` prop.
    - Styling: Centered image with reasonable max-width, checkerboard background behind the image to show transparency (CSS pattern using repeating-linear-gradient or a tiny checkerboard SVG).

    **src/components/App.tsx** (rewrite the skeleton from Plan 01):
    - This is the MAIN wiring component. State management lives here.
    - **Worker creation:** Create the worker using the exact Vite pattern -- MUST be inline, not abstracted:
      ```typescript
      const workerRef = useRef<Worker | null>(null);
      useEffect(() => {
        workerRef.current = new Worker(
          new URL("../workers/inference.worker.ts", import.meta.url),
          { type: "module" }
        );
        // Send load-model immediately for eager loading
        workerRef.current.postMessage({ type: "load-model" });
        return () => { /* Do NOT terminate -- WASM memory leak pitfall */ };
      }, []);
      ```

    - **State:** `modelStatus: ModelStatus`, `downloadProgress: DownloadProgress | null`, `isProcessing: boolean`, `resultUrl: string | null`, `originalFile: File | null`, `error: string | null`.

    - **Worker message handler:** In useEffect, attach `worker.onmessage`. Handle all WorkerOutMessage types:
      - `model-progress`: Update downloadProgress. Use a Map ref to track per-file loaded/total, sum across files for total progress. Guard with optional chaining. Set modelStatus to "downloading" on first progress event.
      - `model-ready`: Set modelStatus to "ready".
      - `model-error`: Set modelStatus to "error", set error message.
      - `inference-start`: (optional logging)
      - `inference-complete`: Call `compositeFullResolution(originalFile, maskData)`, create Blob URL via `URL.createObjectURL()`, set resultUrl, set isProcessing to false.
      - `inference-error`: Set error, set isProcessing to false.

    - **Drop handler:** When file is dropped: set originalFile, set isProcessing to true, clear previous resultUrl (revoke old Blob URL with `URL.revokeObjectURL`), post `{ type: "process", imageId: "single", imageData: file }` to worker.

    - **Reset handler:** Revoke Blob URL, clear resultUrl, clear originalFile, clear error.

    - **Render:** Conditional rendering based on state:
      - Always show ModelProgress at top when model is not ready
      - Show crossOriginIsolated status indicator (small text at bottom)
      - If no result and not processing: Show DropZone
      - If processing: Show "Processing..." indicator with a simple spinner or pulsing animation
      - If result: Show ResultView

    - **Cleanup:** In useEffect cleanup, revoke any active Blob URL to prevent memory leaks.

    IMPORTANT: The `new URL("../workers/inference.worker.ts", import.meta.url)` MUST appear directly inside `new Worker()`. Vite statically analyzes this pattern. Do NOT extract the URL to a variable.
  </action>
  <verify>
    1. `npx vite build` succeeds -- all components compile cleanly
    2. `src/components/App.tsx` contains `new Worker(new URL("../workers/inference.worker.ts", import.meta.url)` (exact Vite pattern)
    3. `src/components/App.tsx` imports and calls `compositeFullResolution`
    4. `src/components/App.tsx` calls `URL.createObjectURL` and `URL.revokeObjectURL`
    5. `src/components/ModelProgress.tsx` shows "one-time" messaging
    6. `src/components/ResultView.tsx` has download link with `_nobg.png` suffix
    7. `src/components/DropZone.tsx` validates image file types
    8. All components use Tailwind classes for styling (no CSS modules or styled-components)
    9. `npx vite dev` starts and the page renders (manual verification in checkpoint)
  </verify>
  <done>
    All four components exist and compile. App.tsx wires Worker creation (with eager model loading), drop handling, inference dispatch, compositor call, and result display. Components use typed props matching the types from lib/types.ts. Build succeeds.
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <name>Task 3: Verify end-to-end background removal flow</name>
  <what-built>
    Complete end-to-end single-image background removal pipeline:
    - Project scaffold with Vite + React + Tailwind + TypeScript
    - coi-serviceworker for cross-origin isolation
    - Web Worker with RMBG-1.4 AI model (singleton, progress tracking, Safari workaround)
    - Canvas compositor for full-resolution output
    - Minimal UI: drop zone, model progress bar, result display with download
  </what-built>
  <how-to-verify>
    1. Run `npx vite dev` (or `npm run dev`) in the project root
    2. Open the URL shown in terminal (typically http://localhost:5173/BatchClear.io/)
    3. **Check cross-origin isolation:** Look for the crossOriginIsolated status indicator in the UI. It should show `true`. Also verify in browser console: type `crossOriginIsolated` and confirm it returns `true`.
    4. **First-time model download:** Drop any image onto the drop zone. The model download progress bar should appear showing MB downloaded / total MB with "one-time download" messaging. This will download ~45MB on first use.
    5. **Processing:** After model loads, inference should begin automatically. UI should remain responsive (try scrolling or interacting while it processes).
    6. **Result:** A background-removed PNG should appear. Verify:
       - The transparent areas show through the checkerboard pattern
       - The image is at the ORIGINAL resolution (not 1024x1024) -- check by downloading and inspecting dimensions
       - The download link works and saves a file with `_nobg.png` suffix
    7. **Cached model:** Click "Process another", drop a second image. This time the model should load instantly (no download progress bar), going straight to inference.
    8. **Network check:** Open DevTools Network tab. During the SECOND image processing, verify zero network requests are made (all inference is local).

    Expected issues to report (not blockers):
    - First page load may trigger a reload (coi-serviceworker installing) -- this is expected behavior
    - Safari may be slower (single-threaded mode) -- expected per the Safari workaround
  </how-to-verify>
  <resume-signal>Type "approved" if end-to-end flow works, or describe any issues you see.</resume-signal>
</task>

</tasks>

<verification>
Phase 1 verification checklist (all must pass):

1. `crossOriginIsolated === true` in browser console on dev server
2. User can drop an image and receive a background-removed PNG
3. Output image is at original resolution (not 1024x1024)
4. Model download progress shows MB loaded / total with "one-time download" messaging
5. UI remains responsive during processing (Web Worker isolation)
6. Second image processes without model re-download (cached)
7. Zero network requests during image processing (after model is cached)
8. `npm run build` produces clean dist/ output
</verification>

<success_criteria>
- End-to-end flow works: drop image -> model downloads (first time) -> inference runs -> full-res PNG output displayed
- crossOriginIsolated === true on dev server
- Model download progress bar with MB counters and one-time messaging
- Result image at original resolution with transparent background
- Clean build output
- UI never freezes during processing
</success_criteria>

<output>
After completion, create `.planning/phases/01-foundation/01-02-SUMMARY.md`
</output>
